# 基础

> 参考：https://zhuanlan.zhihu.com/p/88597686 
>
> http://www.topgoer.com/%E5%BE%AE%E6%9C%8D%E5%8A%A1/RPC.html

RPC（Remote Procedure Call）：远程过程调用，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的思想。 RPC 是一种技术思想而非一种规范或协议，常见 RPC 技术和框架有：

- 应用级的服务框架：阿里的 Dubbo/Dubbox、Google gRPC、Spring Boot/Spring Cloud。
- 远程通信协议：RMI、Socket、SOAP(HTTP XML)、REST(HTTP JSON)。
- 通信框架：MINA 和 Netty。

在一个典型 RPC 的使用场景中，包含了服务发现、负载、容错、网络传输、序列化等组件，其中RPC 协议就指明了程序如何进行网络传输和序列化。

![img](https://pic1.zhimg.com/80/v2-fd76ff73dfc5e4c482ab3713f528dd20_720w.jpg)

一个 RPC 的核心功能主要有 5 个部分组成，分别是：客户端、客户端 Stub、网络传输模块、服务端 Stub、服务端等。 

- 客户端（Client）：服务调用方。
- 客户端存根（Client Stub）：存放服务端地址信息，将客户端的请求参数数据信息打包成网络消息，再通过网络传输发送给服务端。
- 服务端存根（Server Stub）：接收客户端发送过来的请求消息并进行解包，然后再调用本地服务进行处理。
- 服务端（Server）：服务的真正提供者。
- Network Service：底层传输，可以是 TCP 或 HTTP。

一次 RPC 调用流程如下：

- 服务消费者（Client 客户端）通过本地调用的方式调用服务。
- 客户端存根（Client Stub）接收到调用请求后负责将方法、入参等信息序列化（组装）成能够进行网络传输的消息体。找到远程的服务地址，将消息通过网络发送给服务端。
- 服务端存根（Server Stub）收到消息后进行解码（反序列化操作）。根据解码结果调用本地的服务进行相关处理。
- 服务端(Server)本地服务进行业务处理。处理结果返回给服务端存根（Server Stub）。
- 服务端存根（Server Stub）序列化结果。将结果通过网络发送至消费方。
- 客户端存根（Client Stub）接收到消息，并进行解码（反序列化）。
- 服务消费方得到最终结果。

实现rpc的三个技术点：

1、服务寻址

客户端在做远程过程调用时，必须附上这个 ID。然后我们还需要在客户端和服务端分别维护一个函数和Call ID的对应表。  当客户端需要进行远程调用时，它就查一下这个表，找出相应的 Call ID，然后把它传给服务端，服务端也通过查表，来确定客户端需要调用的函数，然后执行相应函数的代码。  实现方式：服务注册中心通过Zookeeper。 

2、数据流的序列化和反序列化

客户端把参数先转成一个字节流，传给服务端后，再把字节流转成自己能读取的格式。只有二进制数据才能在网络中传输，序列化和反序列化的定义是：将对象转换成二进制流的过程叫做序列化；将二进制流转换成对象的过程叫做反序列化。从服务端返回的值也需要序列化反序列化的过程。

3、网络传输

网络传输层需要把 Call ID 和序列化后的参数字节流传给服务端，然后再把序列化后的调用结果传回客户端。尽管大部分 RPC 框架都使用 TCP 协议，但其实 UDP 也可以，而 gRPC 干脆就用了 HTTP2。

**基于 TCP 协议的 RPC 调用** 

由服务的调用方与服务的提供方建立 Socket 连接，并由服务的调用方通过 Socket 将需要调用的接口名称、方法名称和参数序列化后传递给服务的提供方，服务的提供方反序列化后再利用反射调用相关的方法。  最后将结果返回给服务的调用方，整个基于 TCP 协议的 RPC 调用大致如此。  但是在实例应用中则会进行一系列的封装，如 RMI 便是在 TCP 协议上传递可序列化的 Java 对象。  

**基于 HTTP 协议的 RPC 调用** 

该方法更像是访问网页一样，只是它的返回结果更加单一简单。  其大致流程为：由服务的调用者向服务的提供者发送请求，这种请求的方式可能是 GET、POST、PUT、DELETE 等中的一种，服务的提供者可能会根据不同的请求方式做出不同的处理，或者某个方法只允许某种请求方式。  而调用的具体方法则是根据 URL 进行方法调用，而方法所需要的参数可能是对服务调用方传输过去的 XML 数据或者 JSON 数据解析后的结果，最后返回 JOSN 或者 XML 的数据结果。  由于目前有很多开源的 Web 服务器，如 Tomcat，所以其实现起来更加容易，就像做 Web 项目一样。  

**RPC 和 Restful API 对比**
面对对象不同：RPC 更侧重于动作。REST 的主体是资源。RESTful 是面向资源的设计架构，但在系统中有很多对象不能抽象成资源，比如登录，修改密码等而 RPC 可以通过动作去操作资源。所以在操作的全面性上 RPC 大于 RESTful。

传输效率：RPC 效率更高。RPC，使用自定义的 TCP 协议，可以让请求报文体积更小，或者使用 HTTP2 协议，也可以很好的减少报文的体积，提高传输效率。

复杂度：RPC 实现复杂，流程繁琐。REST 调用及测试都很方便。RPC 实现需要实现编码，序列化，网络传输等。而 RESTful 不要关注这些，RESTful 实现更简单。

灵活性：HTTP 相对更规范，更标准，更通用，无论哪种语言都支持 HTTP 协议。RPC 可以实现跨语言调用，但整体灵活性不如 RESTful。

总结：RPC 主要用于公司内部的服务调用，性能消耗低，传输效率高，实现复杂。
REST 主要用于对外的异构环境，浏览器接口调用，App 接口调用，第三方接口调用等。微服务架构下数据交互一般是对内 RPC，对外 REST。

# grpc

## 介绍

> 参考：https://cloud.tencent.com/developer/article/1485722

**特性**

1. gRPC基于服务的思想：定义一个服务，描述这个服务的方法以及入参出参，服务器端有这个服务的具体实现，客户端保有一个存根，提供与服务端相同的服务

2. gRPC默认采用protocol buffer作为IDL(Interface Description Lanage)接口描述语言,服务之间通信的数据序列化和反序列化也是基于protocol buffer的，因为protocol buffer的特殊性，所以gRPC框架是跨语言的通信框架（与编程语言无关性），也就是说用Java开发的基于gRPC的服务，可以用GoLang编程语言调用

3. gRPC同时支持同步调用和异步调用，同步RPC调用时会一直阻塞直到服务端处理完成返回结果， 异步RPC是客户端调用服务端时不等待服务段处理完成返回，而是服务端处理完成后主动回调客户端告诉客户端处理完成

4. gRPC是基于http2协议实现的，http2协议提供了很多新的特性，并且在性能上也比http1提高了许多，所以gRPC的性能是非常好的

5. 长连接。gRPC连接是粘性的。这意味着当从客户端到服务器建立连接时，相同的连接将被尽可能长时间地用于许多请求（多路复用）。这样做是为了避免所有最初的时间和资源花费在TCP握手上。因此，当客户端获取与服务器实例的连接时，它将保持连接。 

6. gRPC并没有直接实现负载均衡和服务发现的功能，但是已经提供了自己的设计思路。已经为命名解析和负载均衡提供了接口

7. 基于http2协议的特性：gRPC允许定义如下四类服务方法

   单项RPC：客户端发送一次请求，等待服务端响应结构，会话结束，就像一次普通的函数调用这样简单

   服务端流式RPC：客户端发起一起请求，服务端会返回一个流，客户端会从流中读取一系列消息，直到没有结果为止

   客户端流式RPC：客户端提供一个数据流并写入消息发给服务端，一旦客户端发送完毕，就等待服务器读取这些消息并返回应答

   双向流式RPC：客户端和服务端都一个数据流，都可以通过各自的流进行读写数据，这两个流是相互独立的，客户端和服务端都可以按其希望的任意顺序独写

**gRPC的使用场景**

1. 低延迟，高度可扩展的分布式系统
2. 开发与[云服务器](https://cloud.tencent.com/product/cvm?from=10680)通信的客户端
3. 设计一个准确，高效，且与语言无关的新协议时
4. 分层设计，以实现扩展，例如。身份验证，负载平衡，日志记录和监控等

**gRPC设计的动机和原则**

1. 自由，开放：让所有人，所有平台都能使用，其实就是开源，跨平台，跨语言
2. 协议可插拔：不同的服务可能需要使用不同的消息通信类型和编码机制，例如，JSON、XML和 Thirft,所以协议应允许可插拔机制，还有负载均衡，服务发现，日志，监控等都支持可插拔机制
3. 阻塞和非阻塞：支持客户端和服务器交换的消息序列的异步和同步处理。这对于在某些平台上扩展和处理至关重要
4. 取消和超时：一次RPC操作可能是持久并且昂贵的，应该允许客户端设置取消RPC通信和对这次通信加上一个超时时间
5. 拒绝：必须允许服务器通过在继续处理请求的同时拒绝新请求的到来并优雅地关闭。
6. 流处理：存储系统依靠流和流控制来表达大型数据集，其他服务，如语音到文本或股票行情，依赖于流来表示与时间相关的消息序列
7. 流控制：计算能力和网络容量在客户端和服务器之间通常是不平衡的。流控制允许更好的缓冲区管理，以及过度活跃的对等体提供对DOS的保护。
8. 元数据交换 - 认证或跟踪等常见的跨领域问题依赖于不属于服务声明接口的数据交换。依赖于他们将这些特性演进到服务，暴露API来提供能力。
9. 标准化状态码 - 客户端通常以有限的方式响应API调用返回的错误。应约束状态码名称空间，以使这些错误处理决策更加清晰。如果需要更丰富的特定领域的状态，则可以使用元数据交换机制来提供该状态。
10. 互通性：报文协议(Wire Protocol)必须遵循普通互联网基础框架

## Protobuf

> 参考：https://blog.51cto.com/u_9291927/2332264

**序列化**

序列化是将数据结构或对象转换成二进制字节流的过程。Protobuf对于不同的字段类型采用不同的编码方式和数据存储方式对消息字段进行序列化，以确保得到高效紧凑的数据压缩。Protobuf序列化过程如下：

（1）判断每个字段是否有设置值，有值才进行编码。
（2）根据字段标识号与数据类型将字段值通过不同的编码方式进行编码。
（3）将编码后的数据块按照字段类型采用不同的数据存储方式封装成二进制数据流。

**反序列化**

反序列化是将在序列化过程中所生成的二进制字节流转换成数据结构或者对象的过程。Protobuf反序列化过程如下：
（1）调用消息类的parseFrom(input)解析从输入流读入的二进制字节数据流。
（2）将解析出来的数据按照指定的格式读取到Java、C++、Phyton对应的结构类型中。

**编码方式**

Varint编码是一种变长的编码方式，编码原理是用字节表示数字，值越小的数字，使用越少的字节数表示。因此，可以通过减少表示数字的字节数进行数据压缩。 

Zigazg编码是一种变长的编码方式，其编码原理是使用无符号数来表示有符号数字，使得绝对值小的数字都可以采用较少字节来表示，特别对表示负数的数据能更好地进行数据压缩。 

**数据存储方式**

T-L-V数据存储方式。T-L-V（Tag - Length - Value），即标识符-长度-字段值的存储方式，其原理是以标识符-长度-字段值表示单个数据，最终将所有数据拼接成一个字节流，从而实现数据存储的功能。

T-V数据存储方式。消息字段的标识号、数据类型、字段值经过Protobuf采用Varint和Zigzag编码后，以T-V（Tag-Value）方式进行数据存储。

**数据存储的三大原则**

1. Protocol Buffer将消息中的每个字段进行编码后，利用T - L - V 存储方式进行数据的存储，最终得到一个二进制字节流。 
2. ProtoBuf对于不同数据类型采用不同的序列化方式（数据编码方式与数据存储方式） Protobuf对于不同的字段类型采用不同的编码和数据存储方式对消息字段进行序列化，以确保得到高效紧凑的数据压缩。 对于Varint编码数据的存储，不需要存储字节长度Length，使用T-V存储方式进行存储；对于采用其它编码方式（如LENGTH_DELIMITED）的数据，使用T-L-V存储方式进行存储。 
3. ProtoBuf对于数据字段值的独特编码方式与T-L-V数据存储方式，使得 ProtoBuf序列化后数据量体积极小 。

**Protobuf使用建议**

1. 多用 optional或 repeated修饰符  若optional 或 repeated 字段没有被设置字段值，那么该字段在序列化时的数据中是完全不存在的，即不需要进行编码，但相应的字段在解码时会被设置为默认值。 
2. 字段标识号（Field_Number）尽量只使用1-15，且不要跳动使用 Tag是需要占字节空间的。如果Field_Number>16时，Field_Number的编码就会占用2个字节，那么Tag在编码时就会占用更多的字节；如果将字段标识号定义为连续递增的数值，将获得更好的编码和解码性能。 
3. 若需要使用的字段值出现负数，请使用sint32/sint64，不要使用int32/int64。 采用sint32/sint64数据类型表示负数时，会先采用Zigzag编码再采用Varint编码，从而更加有效压缩数据。 
4. 对于repeated字段，尽量增加packed=true修饰 增加packed=true修饰，repeated字段会采用连续数据存储方式，即T - L - V - V -V方式。 

## 负载均衡

> 参考：https://pandaychen.github.io/2019/07/11/GRPC-SERVICE-DISCOVERY/

在大型的微服务系统中，我们会为同一个服务部署多个节点， 以便服务可以支持大并发的访问。它们可能部署在同一个数据中心的多个节点，或者多个数据中心中。 客户端通过负载均衡器LB选择一个节点。

### 分类

负载均衡器LB根据位置的不同，大致上分为三种：

1、集中式 LB（Proxy Model）

独立的 LB，如 nginx 
![image](https://image-static.segmentfault.com/376/097/3760970390-58c6367e9e8e5_articlex)

2、进程内 LB（Balancing-aware Client）

进程内 LB（集成到客户端），此方案将 LB 的功能集成到服务消费方进程里，也被称为软负载或者客户端负载方案。服务提供方启动时，首先将服务地址注册到服务注册表，同时定期报心跳到服务注册表以表明服务的存活状态，相当于健康检查，服务消费方要访问某个服务时，它通过内置的 LB 组件向服务注册表查询，同时缓存并定期刷新目标服务地址列表，然后以某种负载均衡策略选择一个目标服务地址，最后向目标服务发起请求。LB 和服务发现能力被分散到每一个服务消费者的进程内部，同时服务消费方和服务提供方之间是直接调用，没有额外开销，性能比较好。

![image](https://image-static.segmentfault.com/816/567/816567186-58c636a93e391_articlex)

3、独立 LB 进程（External Load Balancing Service）

   该方案是针对上一种方案的不足而提出的一种折中方案，原理和第二种方案基本类似。不同之处是将 LB 和服务发现功能从进程内移出来，变成主机上的一个独立进程。主机上的一个或者多个服务要访问目标服务时，他们都通过同一主机上的独立 LB 进程做服务发现和负载均衡。该方案也是一种分布式方案没有单点问题，一个 LB 进程挂了只影响该主机上的服务调用方，服务调用方和 LB 之间是进程内调用性能好，同时该方案还简化了服务调用方，不需要为不同语言开发客户库，LB 的升级不需要服务调用方改代码。![img](https://image-static.segmentfault.com/157/460/1574606891-58c636b7d0619_articlex)

### grpc方案

负载均衡基本实现过程：

1. 构建注册中心，这里注册中心一般要求具备分布式一致性（满足 CAP 定理的 AP 或 CP）的高可用的组件集群，如 Zookeeper、Consul、Etcd 等
2. 构建 gRPC 服务端的注册逻辑，服务启动后定时向注册中心注册自身的关键信息（一般开启新的 groutine 来完成），至少包含 IP 和端口，其他可选信息，如自身的负载信息（CPU 和 Memory）、当前实时连接数等，这些辅助信息有助于帮助系统更好的执行 LB 算法
3. 获取服务地址：gRPC 客户端向注册中心发出服务解析请求，注册中心将请求中关联的所有服务的信息返回给 gRPC 客户端，客户端与所有在线的服务建立起 HTTP2 长连接
4. gRPC 客户端发起 RPC 调用，根据 LB 均衡器中实现的负载均衡策略（gRPC 中默认提供的算法是 RoundRobin），选择其中一 HTTP2 长连接进行通信，即 LB 策略决定哪个子通道 - 即哪个 gRPC 服务器将接收请求

对于负载均衡gRPC 提供的接口：

- Resolver：解析器，用于从注册中心实时获取当前服务端的列表，同步发送给Balancer  
- Balancer：平衡器，一是接收从 Resolver 发送的服务端列表，建立并维护（长）连接状态；二是每次当 Client 发起 Rpc 调用时，按照一定算法从连接池中选择一个连接进行 Rpc 调用
- Register：注册，用于服务端初始化和在线时，将自己信息上报到注册中心，主要信息有 Ip，端口等

采用了 gRPC 与 Etcd 的服务治理方案优点：

- 采用了 gRPC 实现负载均衡策略，模块之间通信采用长连接方式，避免每次 RPC 调用时新建连接的开销，充分发挥 HTTP2 的优势
- 扩容和缩容都及其方便，例如扩容，只要部署上服务，运行后，服务成功注册到 Etcd 便大功告成
- 灵活的自定义的 LB 算法，使得后端压力更为均衡
- 客户端加入重试逻辑，使得网络抖动情况下，可以通过重试连接上另外一台服务

### 策略

负载均衡策略有：随机、轮询、一致性哈希、加权、网络质量优先（ping节点的网络）、地理位置优先（在注册中心配置节点的经纬度）、定制路由规则。

1、RoundRobin（轮询）
2、Weight-RoundRobin（加权轮询）
不同的后端服务器可能机器的配置和当前系统的负载并不相同，因此它们的抗压能力也不相同。给配置高、负载低的机器配置更高的权重，而配置低、负载高的机器，给其分配较低的权重，降低其系统负载，加权轮询能很好地处理这一问题，并将请求顺序且按照权重分配到后端。
3、Random（随机）
4、Weight-Random（加权随机）
通过系统的随机算法，根据后端服务器的列表随机选取其中的一台服务器进行访问
5、源地址哈希法
源地址哈希的思想是根据获取客户端的 IP 地址，通过哈希函数计算得到的一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是客服端要访问服务器的序号。采用源地址哈希法进行负载均衡，同一 IP 地址的客户端，当后端服务器列表不变时，它每次都会映射到同一台后端服务器进行访问
6、最小连接数法
最小连接数算法比较灵活和智能，由于后端服务器的配置不尽相同，对于请求的处理有快有慢，它是根据后端服务器当前的连接情况，动态地选取其中当前积压连接数最少的一台服务器来处理当前的请求，尽可能地提高后端服务的利用效率，将负责合理地分流到每一台服务器
7、一致性哈希算法
常见的是 Ketama 算法，该算法是用来解决 cache 失效导致的缓存穿透的问题的，当然也可以适用于 gRPC 长连接的场景

## 认证

tls、token



## 应用

。。。







